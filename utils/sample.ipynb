{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from ssl import OP_NO_TLSv1\n",
    "import nibabel as nib\n",
    "# from visdom import Visdom\n",
    "# viz = Visdom(port=8850)\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "sys.path.append(\".\")\n",
    "import numpy as np\n",
    "import time\n",
    "import torch as th\n",
    "from PIL import Image\n",
    "import torch.distributed as dist\n",
    "from guided_diffusion import dist_util, logger\n",
    "from guided_diffusion.bratsloader import BRATSDataset, BRATSDataset3D\n",
    "from guided_diffusion.isicloader import ISICDataset\n",
    "from guided_diffusion.amosloader import AMOSDataset3D\n",
    "import torchvision.utils as vutils\n",
    "from guided_diffusion.utils import staple\n",
    "from guided_diffusion.script_util import (\n",
    "    NUM_CLASSES,\n",
    "    model_and_diffusion_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    add_dict_to_argparser,\n",
    "    args_to_dict,\n",
    ")\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "seed=10\n",
    "th.manual_seed(seed)\n",
    "th.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def visualize(img):\n",
    "    _min = img.min()\n",
    "    _max = img.max()\n",
    "    normalized_img = (img - _min)/ (_max - _min)\n",
    "    return normalized_img\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = create_argparser().parse_args()\n",
    "    dist_util.setup_dist(args)\n",
    "    logger.configure(dir = args.out_dir)\n",
    "\n",
    "    if args.data_name == 'ISIC':\n",
    "        tran_list = [transforms.Resize((args.image_size,args.image_size)), transforms.ToTensor(),]\n",
    "        transform_test = transforms.Compose(tran_list)\n",
    "\n",
    "        ds = ISICDataset(args, args.data_dir, transform_test, mode = 'Test')\n",
    "        args.in_ch = 4\n",
    "    elif args.data_name == 'BRATS':\n",
    "        tran_list = [transforms.Resize((args.image_size,args.image_size)),]\n",
    "        transform_test = transforms.Compose(tran_list)\n",
    "\n",
    "        ds = BRATSDataset3D(args.data_dir,transform_test)\n",
    "        args.in_ch = 5\n",
    "    elif args.data_name == 'AMOS':\n",
    "        tran_list = [transforms.Resize((args.image_size,args.image_size)),]\n",
    "        transform_train = transforms.Compose(tran_list)\n",
    "\n",
    "        ds = AMOSDataset3D(args.data_dir, transform_train, args.crop_size, phase=\"Va\")\n",
    "        args.in_ch = args.crop_size * 2\n",
    "        \n",
    "    datal = th.utils.data.DataLoader(\n",
    "        ds,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True)\n",
    "    data = iter(datal)\n",
    "\n",
    "    logger.log(\"creating model and diffusion...\")\n",
    "\n",
    "    random.seed(int(time.time() % 9999))\n",
    "    model, diffusion = create_model_and_diffusion(\n",
    "        **args_to_dict(args, model_and_diffusion_defaults().keys())\n",
    "    )\n",
    "    all_images = []\n",
    "    \n",
    "    # from collections import OrderedDict\n",
    "    # new_state_dict = OrderedDict()\n",
    "            \n",
    "    # if args.multi_gpu:\n",
    "    #     state_dict = dist_util.load_state_dict(args.model_path, map_location={f\"cuda:{i}\" : f\"cuda:{i}\" for i in args.multi_gpu.split(',')})\n",
    "    #     for k, v in state_dict.items():\n",
    "    #         # name = k[7:] # remove `module.`\n",
    "    #         if 'module.' in k:\n",
    "    #             new_state_dict[k] = v\n",
    "    #             # load params\n",
    "    #         else:\n",
    "    #             new_state_dict = state_dict\n",
    "    #         model.to(dist_util.dev())\n",
    "    #         # state_dict = dist_util.load_state_dict(args.model_path, map_location=\"cuda:0\")\n",
    "\n",
    "    #     model = th.nn.DataParallel(model,device_ids=[int(id) for id in args.multi_gpu.split(',')])\n",
    "    #     model.to(device = th.device('cuda', int(args.gpu_dev)))\n",
    "    #     # state_dict = dist_util.load_state_dict(args.model_path, map_location={f\"cuda:{i}\" : f\"cuda:{i}\" for i in args.multi_gpu.split(',')})\n",
    "    # else:\n",
    "    #     state_dict = dist_util.load_state_dict(args.model_path, map_location=\"cuda:0\")\n",
    "    #     for k, v in state_dict.items():\n",
    "    #         # name = k[7:] # remove `module.`\n",
    "    #         if 'module.' in k:\n",
    "    #             new_state_dict[k[7:]] = v\n",
    "    #             # load params\n",
    "    #         else:\n",
    "    #             new_state_dict = state_dict\n",
    "    #         model.to(dist_util.dev())\n",
    "    #         # state_dict = dist_util.load_state_dict(args.model_path, map_location=\"cuda:0\")\n",
    "\n",
    "    # model.load_state_dict(new_state_dict)\n",
    "    \n",
    "    device = th.device(\"cuda:0\")\n",
    "    \n",
    "    state_dict = dist_util.load_state_dict(args.model_path, map_location=\"cuda:0\")\n",
    "    # print(state_dict.keys())\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        # name = k[7:] # remove `module.`\n",
    "        if 'module.' in k:\n",
    "            new_state_dict[k[7:]] = v\n",
    "            # load params\n",
    "        else:\n",
    "            new_state_dict = state_dict\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "    model.to(dist_util.dev())\n",
    "    if args.use_fp16:\n",
    "        model.convert_to_fp16()\n",
    "    model.eval()\n",
    "    for _ in range(len(data)):\n",
    "        mask_ch = args.crop_size if args.data_name == 'AMOS' else 1\n",
    "        b, m, path = next(data)  #should return an image from the dataloader \"data\"\n",
    "        c = th.randn_like(b[:, :mask_ch, ...])\n",
    "        img = th.cat((b, c), dim=1)     #add a noise channel$\n",
    "        if args.data_name == 'ISIC':\n",
    "            slice_ID=path[0].split(\"_\")[-1].split('.')[0]\n",
    "        elif args.data_name == 'BRATS':\n",
    "            # slice_ID=path[0].split(\"_\")[2] + \"_\" + path[0].split(\"_\")[4]\n",
    "            slice_ID=path[0].split(\"_\")[-3] + \"_\" + path[0].split(\"slice\")[-1].split('.nii')[0]\n",
    "        elif args.data_name == 'AMOS':\n",
    "            print(path)\n",
    "            slice_ID = path[0].split('.')[0]\n",
    "\n",
    "        logger.log(\"sampling...\")\n",
    "\n",
    "        start = th.cuda.Event(enable_timing=True)\n",
    "        end = th.cuda.Event(enable_timing=True)\n",
    "        enslist = []\n",
    "\n",
    "        for i in range(args.num_ensemble):  #this is for the generation of an ensemble of 5 masks.\n",
    "            print(f'Ensemble step {i} started...')\n",
    "            t0 = time.time()\n",
    "            ch = args.crop_size if args.data_name == 'AMOS' else 3\n",
    "            model_kwargs = {}\n",
    "            start.record()\n",
    "            sample_fn = (\n",
    "                diffusion.p_sample_loop_known if not args.use_ddim else diffusion.ddim_sample_loop_known\n",
    "            )\n",
    "            sample, x_noisy, org, cal, cal_out = sample_fn(\n",
    "                model,\n",
    "                (args.batch_size, ch, args.image_size, args.image_size), img,\n",
    "                step = args.diffusion_steps,\n",
    "                clip_denoised=args.clip_denoised,\n",
    "                model_kwargs=model_kwargs,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            print(sample.shape)\n",
    "            print(org.shape)\n",
    "            print(cal.shape)\n",
    "            print(cal_out.shape)\n",
    "            \n",
    "            # tensor2pil = transforms.ToPILImage()\n",
    "            # s = tensor2pil(sample.squeeze())\n",
    "            # o = tensor2pil(org[:,-1,:,:].squeeze() / org[:,-1,:,:].max())\n",
    "            # c = tensor2pil(cal.squeeze())\n",
    "            # c_out = tensor2pil(cal_out.squeeze())\n",
    "            \n",
    "            # s.save(f\"{slice_ID}_s.png\")\n",
    "            # for i in range(org.size()[1]):\n",
    "            #     tensor2pil(org[:,i,:,:].squeeze() / org[:,i,:,:].max()).save(f\"{slice_ID}_o_{i}.png\")\n",
    "            # c.save(f\"{slice_ID}_c.png\")\n",
    "            # c_out.save(f\"{slice_ID}_c_out.png\")\n",
    "            \n",
    "            end.record()\n",
    "            th.cuda.synchronize()\n",
    "            print('time for 1 sample', start.elapsed_time(end))  #time measurement for the generation of 1 sample\n",
    "\n",
    "            co = th.tensor(cal_out)\n",
    "            if args.version == 'new':\n",
    "                enslist.append(sample[:,-1,:,:])\n",
    "            else:\n",
    "                enslist.append(co)\n",
    "\n",
    "            if args.debug:\n",
    "                # print('sample size is',sample.size())\n",
    "                # print('org size is',org.size())\n",
    "                # print('cal size is',cal.size())\n",
    "                if args.data_name == 'ISIC':\n",
    "                    # s = th.tensor(sample)[:,-1,:,:].unsqueeze(1).repeat(1, 3, 1, 1)\n",
    "                    o = th.tensor(org)[:,:-1,:,:]\n",
    "                    c = th.tensor(cal).repeat(1, 3, 1, 1)\n",
    "                    # co = co.repeat(1, 3, 1, 1)\n",
    "\n",
    "                    s = sample[:,-1,:,:]\n",
    "                    b,h,w = s.size()\n",
    "                    ss = s.clone()\n",
    "                    ss = ss.view(s.size(0), -1)\n",
    "                    ss -= ss.min(1, keepdim=True)[0]\n",
    "                    ss /= ss.max(1, keepdim=True)[0]\n",
    "                    ss = ss.view(b, h, w)\n",
    "                    ss = ss.unsqueeze(1).repeat(1, 3, 1, 1)\n",
    "\n",
    "                    tup = (ss,o,c)\n",
    "                elif args.data_name == 'BRATS':\n",
    "                    s = th.tensor(sample)[:,-1,:,:].unsqueeze(1)\n",
    "                    m = th.tensor(m.to(device = 'cuda:0'))[:,0,:,:].unsqueeze(1)\n",
    "                    # input 4개라서 o1 o2 o3 o4 48개니까 \n",
    "                    o1 = th.tensor(org)[:,0,:,:].unsqueeze(1)\n",
    "                    o2 = th.tensor(org)[:,1,:,:].unsqueeze(1)\n",
    "                    o3 = th.tensor(org)[:,2,:,:].unsqueeze(1)\n",
    "                    o4 = th.tensor(org)[:,3,:,:].unsqueeze(1)\n",
    "                    c = th.tensor(cal)\n",
    "\n",
    "                    tup = (o1/o1.max(),o2/o2.max(),o3/o3.max(),o4/o4.max(),m,s,c,co)\n",
    "                \n",
    "                elif args.data_name == 'AMOS':\n",
    "                    pass\n",
    "\n",
    "                compose = th.cat(tup,0)\n",
    "                vutils.save_image(compose, fp = os.path.join(args.out_dir, str(slice_ID)+'_output'+str(i)+\".jpg\"), nrow = 1, padding = 10)\n",
    "            print(f'Time : {time.time() - t0:.2f}s')\n",
    "        \n",
    "        ensres = staple(th.stack(enslist,dim=0)).squeeze(0)\n",
    "        vutils.save_image(ensres, fp = os.path.join(args.out_dir, str(slice_ID)+'_output_ens'+\".jpg\"), nrow = 1, padding = 10)\n",
    "\n",
    "def create_argparser():\n",
    "    defaults = dict(\n",
    "        data_name = 'BRATS',\n",
    "        data_dir=\"../dataset/brats2020/testing\",\n",
    "        clip_denoised=True,\n",
    "        num_samples=1,\n",
    "        batch_size=1,\n",
    "        crop_size=48,\n",
    "        use_ddim=False,\n",
    "        model_path=\"\",         #path to pretrain model\n",
    "        num_ensemble=5,      #number of samples in the ensemble\n",
    "        gpu_dev = \"0\",\n",
    "        out_dir='./results/',\n",
    "        multi_gpu = None, #\"0,1,2\"\n",
    "        debug = False\n",
    "    )\n",
    "    defaults.update(model_and_diffusion_defaults())\n",
    "    parser = argparse.ArgumentParser()\n",
    "    add_dict_to_argparser(parser, defaults)\n",
    "    return parser\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
